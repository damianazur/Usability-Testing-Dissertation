# Introduction
The README file only shows an overview of the dissertation report and showcases diagrams.<br>
[Read full dissertation here!](https://drive.google.com/file/d/1zlgnvDQijK94nGY5yw5oQHu7yE9cRH0x/)
### Abstract
The return on investment for usability is on average a 135% increase in the desired metrics with only 10% of the budget invested. The design flaws within applications make the applications more difficult to use and these flaws can be discovered through usability testing. The information gathered from a usability test when used to improve the application can improve the user experience leading to greater user productivity, satisfaction and as a result greater profits for the business. 
<br><br>
UsabCheck aims to provide a usability testing suite which can be used to conduct usability studies and to investigate the use of facial expression recognition technology to improve software usability testing and user experience testing. The project involves two applications, one of which is used by the participant to take a usability study and another is used by the researcher to configure tests and to display the data and findings.
<br><br>
The UX researchers and developers who wish to test their software can configure usability studies which involve tasks and questions that participants will complete. During the usability test deep learning is used to automatically detect the participant’s emotions. The data gathered which includes the recording of the participants screen, timestamps of emotions and the participants input is presented to the researcher for further analysis. The advantage of automatically detecting emotions is that it has the potential to help researchers identify the problem areas more easily and effectively in their software.
<br><br>
### Project Scope
The scope of this project involves designing, implementing, testing, and evaluating a usability testing suite with facial expression recognition for desktop machines. The operating system which the testing suite is primary designed for is Windows and the focus will be on website usability testing. However, in theory any software can be tested with the UsabCheck testing suite. The software suite is not designed and not intended for usability testing on mobile devices. The aim is to investigate how facial expression recognition can be applied to usability testing and how the data, which includes emotion data from a conducted usability study can be presented for analysis. 
<br><br>
### Main Conclusions
The project aimed to provide a usability testing software suite and investigate the use and applicability of facial expression recognition in the area of usability testing. The project provides a web application service allowing researchers to create customized usability studies which can be conducted on the UsabCheck local application. The usability study data which includes the screen recordings, participant responses and emotions of the participant are presented to the researcher for analysis. The findings show that the presence of both positive and negative emotions can be a sign of usability problems, however, the lack of emotion does not imply that there are no usability issues. Additionally, as not all emotions experienced by the participants are expressed via their facial expressions and the FER alone cannot be used discover all usability flaws. Means of displaying emotions on a timeline has been developed and it allows the researcher to clearly view and analyse the participant’s expressible emotions. The applicability of FER in usability testing is the improved navigation of the screen recordings of the usability study as the emotion timestamps provide the researcher with another layer by which they can navigate the video. 
<br><br>
It should be also noted that the sample size of participants who participated in the usability study is only 3, all of whom where close friends and family of the author and took part in the usability study from the comfort of their own home. This sense of familiarity may have resulted in the participants expressing more visible emotion than they otherwise would in a professional usability testing setting. As a result of this small sample size and familiarity variable more research is needed.


# Diagrams
## High Level View & Architecture
### Architecture of Applications
<img src="Images/Architecture of Applications.png" width="600"><br>
### High Level View of System
<img src="Images/High Level View of System.png" width="600"><br>
### Development Sections
<img src="Images/Development Sections.png" width="600"><br>

## Backend
### Relationship Between Packages
<img src="Images/Relationship Between Packages.png" width="600"><br>
### Web App Backend Java Classes
<img src="Images/Web App Backend Java Classes.png" width="600"><br>

## Frontend
### Web App Class Front-end Relationships
<img src="Images/Web App Class Front-end Relationships.png" width="600"><br>
### Web App Front-end Classes.png
<img src="Images/Web App Front-end Classes.png" width="600"><br>

## Database
### Web Application ERD
<img src="Images/Web Application ERD.png" width="600"><br>

## Facial Expression Recognition (FER)
### Model 1 Diagram
<img src="Images/Model 1 Diagram.png" width="600"><br>
### Model 2 Diagram
<img src="Images/Second Model Architecture.png" width="600"><br>

# Prototypes
## Frontend
### Recordings Tab New Design (Prototype)
<img src="Images/Recordings Tab New Design.png" width="600"><br>
### View Test Results Overview (Individual Task Performance) Prototype
<img src="Images/View Test Results Overview (Individual Task Performance).png" width="600"><br>
### Web Application Dashboard (Prototype)
<img src="Images/Web Application Dashboard.png" width="600"><br>
### Web Application Usability Test Create (Prototype)
<img src="Images/Web Application Usability Test Create.png" width="600"><br>
### Web Application View Usability Results (Overview) Prototype
<img src="Images/Web Application View Usability Results (Overview).png" width="600"><br>

# Use Case Diagrams
### Researcher Setting Up Usability Test Use Case (Second Iteration)
<img src="Images/Researcher Setting Up Usability Test Use Case (Second Iteration).png" width="500"><br>
### Participant Use Case Diagram
<img src="Images/Participant Use Case Diagram.png"><br>

# Spring Planning & Steps
### Sprint Chart Overview (All Stages)
<img src="Images/Sprint Chart Overview (All Stages).png" width="1500"><br>
### Project Tasks & Requirements
<img src="Images/Project Tasks & Requirements.png" width="600"><br>
### Web App & Local App Subproject High Level Steps
<img src="Images/Web App & Local App Subproject High Level Steps.png" width="600"><br>
### FER Subproject High Level Steps
<img src="Images/FER Subproject High Level Steps.png" width="600"><br>
### Testing and Evaluation Overview
<img src="Images/Testing and Evaluation Overview.png" width="600"><br>

# UI & FER Results
## Web Application UI
### Dashboard (Project Selected & There are Usability Tests)
<img src="Images/Dashboard (Project Selected & There are Usability Tests).png" width="600"><br>
### Create Test (Body of Usability Study)
<img src="Images/Create Test (Body of Usability Study).png" width="600"><br>
### Create Test (Initial Screen)
<img src="Images/Create Test (Initial Screen).png" width="600"><br>
### Information Popups
<img src="Images/Information Popups.png" width="600"><br>
### Create Test (Pre-Test Questions)
<img src="Images/Create Test (Pre-Test Questions).png" width="600"><br>
### View Test Details
<img src="Images/View Test Details.png" width="600"><br>
### View Test Results Overview (Individual Task Performance)
<img src="Images/View Test Results Overview (Individual Task Performance).png" width="600"><br>
### View Test Results Overview (Multiple-Choice Question Answers)
<img src="Images/View Test Results Overview (Multiple-Choice Question Answers).png" width="600"><br>
### View Test Results Recordings (View Video)
<img src="Images/View Test Results Recordings (View Video).png" width="600"><br>
### Video Timeline Bars
<img src="Images/Video Timeline Bars.png" width="600"><br>
### Test Results Recording Tab (Task Grading)
<img src="Images/Test Results Recording Tab (Task Grading).png" width="600"><br>

## Local Python Application UI
### Initial Screen
<img src="Images/Initial Screen.png" width="600"><br>
### Initial Screen (After Data Retrieval)
<img src="Images/Initial Screen (After Data Retrieval).png" width="600"><br>
### Multiple-Choice Question Window
<img src="Images/Multiple-Choice Question Window.png" width="600"><br>
### Task Window States
<img src="Images/Task Window States.png" width="600"><br>
### Data and Video Uploading (Initial Screen).png
<img src="Images/Data and Video Uploading (Initial Screen).png" width="600"><br>

## FER
### Confusion Matrices (Model 2 train on FER2013).png
<img src="Images/Confusion Matrices (Model 2 train on FER2013).png" width="600"><br>
### Accuracy Comparisons (Model 2 train on FER2013)
<img src="Images/Accuracy Comparisons (Model 2 train on FER2013).png" width="400"><br>
### Model 1 Camera Feed Predictions
<img src="Images/Model 1 Camera Feed Predictions.png" width="600"><br>
